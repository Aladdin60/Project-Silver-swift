import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load your cash flow data
# Assuming you have a CSV file with 'Date' and 'CashFlow' columns
data = pd.read_excel('time.xlsx')

# Preprocess the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data['CashFlow'].values.reshape(-1, 1))

# Split the data into input (X) and target (y) sequences
sequence_length = 12  # Number of past time steps to use for prediction
X, y = [], []
for i in range(len(scaled_data) - sequence_length):
    X.append(scaled_data[i:i+sequence_length, 0])
    y.append(scaled_data[i+sequence_length, 0])
X, y = np.array(X), np.array(y)

# Reshape X to be [samples, time steps, features]
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential([
    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(units=50),
    Dense(units=1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Evaluate the model
loss = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss}')

# Make predictions
predictions = model.predict(X_test)

# Inverse transform the predictions
predictions = scaler.inverse_transform(predictions)

# Optionally, you can plot the predictions against the actual cash flow values
import matplotlib.pyplot as plt
plt.plot(predictions, label='Predicted Cash Flow')
plt.plot(scaler.inverse_transform(y_test.reshape(-1, 1)), label='Actual Cash Flow')
plt.legend()
plt.show()
